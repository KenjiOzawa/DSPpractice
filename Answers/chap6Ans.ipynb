{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"fErV1sVPXRwG"},"source":["# 第6章　様々な音響信号処理（確認問題の解答）\n","コードのセルを，本文ノートブック chap6.ipynb にコピペして実行してください。"]},{"cell_type":"markdown","metadata":{"id":"Y-HFu4zBXRwH"},"source":["\n","## 6.1 ボイスチェンジャ \n","\n","(1) ボイスチェンジのためにかけた正弦波の周波数が f = 10 [Hz] の場合，元の音声と異なる聞こえにはなるが，「その人の声」という意味では変わらない感じがしたであろう。このことを，スペクトルを観察した結果と関係して考察しなさい。\n","\n","【答】ここで求めているのは 512 点（32 ms）区間のスペクトルです。f = 10 [Hz] の場合には，100 ms の周期で音声の振幅が大→小→（負の）大→小→大とゆっくり変化するので，32 ms の区間内では振幅の変化がさほど大きくありません。つまり，元の音声の振幅全体が「ちょっと小さめ」や「正負反転」のような波形が観測されるので，その区間のスペクトルの外形は，元の音声から大きく変化しません。それゆえ，「その人の声」という性質は保持されます。\n","\n","一方で，f = 10 [Hz] というゆっくりした変化では，音の大小の変化を感じ取ることができます。この場合に感じた元の音声からの音色の変化は，この時間構造の変化によるところの効果が大きいといえます。\n","\n","(2) 上記の (c) では，（これは「平衡変調」の話に関連させたかったので）キャリアとして「単一周波数の正弦波」を用意した。実際の音声について考えるために，そのキャリアを f0 = 1000 [Hz] に加えて 2000 Hz 成分ももつ２成分音として，スペクトルを観察しなさい。\n","\n","【答】(c) の最初のセルで，キャリアを合成する行を以下のとおり編集するだけです。ぜひ，f = 200 [Hz] 以外の値でも試してください。"]},{"cell_type":"code","metadata":{"id":"WOS2cfVBXRwH"},"source":["wave_data = np.sin(2 * np.pi * f0 * t) + np.sin(2 * np.pi * 2 * f0 * t) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G1JEAAZ3XRwK"},"source":["(3) ここで試した方法以外のボイスチェンジャの作戦を調べること。\n","\n","【答】種々の方法があります。例えば，以下です。\n","\n","・時変平衡変調：本文では 例えば f = 200 [Hz] を固定した平衡変調をかけましたが，f = 200 + 100 * sin(2 \\pi t) のように f を時間と共に変化させます。\n","\n","・ヘリウム音声の模擬：7章でボコーダによる音声合成を行います。線形予測係数を求める前に，スペクトルを周波軸上で 3 倍に引き延ばします（線形補間で十分でしょう）。その後に，ボコーダによる音声合成を行えば，ヘリウムガスを吸引・発声したときの声に近くなります。\n","\n","・スペクトルピーク音声：FFTスペクトルで極大値の周辺のみを残して逆FFTすると，フォルマント情報は残りますので，音韻は変わらず音色が変わります。\n","\n","・リング変調：リングバッファを利用し，話速は変化させずピッチだけを高く／低くします。\n","\n","ところで，ボイスチェンジャ（話速が変わらず音色が変わる）の反対で，話速変換（音色は変わらず話速が変わる）という技術もあります。NHK が語学学習用スマホアプリとして配布しており，どのような技術か公開していますので興味のある方は検索してみてください。\n"]},{"cell_type":"markdown","metadata":{"id":"EZq2Cn3jXRwL"},"source":["## 6.2 エフェクタ\n","\n","(1) ここで試した以外に，エフェクタ／エフェクトとして知られているものを調べること。\n","\n","【答】種々のエフェクタ／エフェクトがあります。例えば，以下です。\n","\n","・ディストーション：歪を発生させます。最も簡単なハードクリッピングでは，波形の絶対値がある値を超えたら，頭打ちにしてしまいます。それゆえ，リミッタとも呼ばれます。\n","\n","・コンプレッサ：上記のリミッタでは特定の値を上回ると定数にしてしまいますが，コンプレッサーでは特定の値を上回った波形を一定の振幅比で圧縮します。小さい音が相対的に大きくなるので，存在感が上がると評価する人もいます。\n","\n","・ワウ：BPFの通過帯域を時間とともに変化させてフィルタリングすることで，「ワ」「ウ」と聞こえるような効果があります。\n","\n","・コーラス：ビブラートなどにより音色に色づけした音を，原音に重ねます。これにより，独唱データから疑似的な合唱データを生成できます。\n","\n","\n","(2) ディストーションと呼ばれるエフェクトを実装して，聴感上の効果を確認すること。\n","\n","【答】インプット 6.6 を修正してみます。"]},{"cell_type":"code","metadata":{"id":"DjAfsHbYXRwL"},"source":["# インプット 6.6 を修正したもの\n","fs, wave_data = scipy.io.wavfile.read ('sample/sample3.wav')  # 音楽データを読み込みます。\n","\n","sampling_interval = 1.0 / fs                  # サンプリング間隔は，サンプリング周波数の逆数\n","times = np.arange ( len ( wave_data )) * sampling_interval  # サンプル系列の時刻データの配列\n","\n","plt.subplot(211)\n","plt.title(\"Output 7.6\")\n","plot_wave(times, wave_data) \n","\n","# 以下で，ディストーションをかけます。\n","limit = 2000.0   # この値を様々に変えて効果を確認してください。\n","distortion = np.copy(wave_data)\n","distortion[ distortion >=  limit] =  limit \n","distortion[ distortion <= -limit] = -limit \n","\n","plt.subplot(212)\n","plot_wave(times, distortion) \n","\n","audio = Audio(distortion, rate = fs)\n","audio"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QAF01MloXRwP"},"source":["## 6.3 マイクロホンアレイによるビームフォーミング\n","\n","(1) ここでは，雑音の低減を耳で確認してきた。一般には，雑音低減量 [dB] は以下で定義される。\n","$$\n","雑音低減量 {\\rm [dB]} = 10 \\log_{10} \\frac{処理後の雑音パワー}{処理前の雑音パワー}\n","$$\n","「処理前」と「処理後」2つの音を与えたときに低減量を算出する関数を定義して，実際に「(a) ステップ3」について雑音低減量を計算しなさい。\n","\n","【答】以下に「処理前」と「処理後」の2つの音を与えた場合に低減量を算出する関数 supression_cal の定義を示します。"]},{"cell_type":"code","metadata":{"id":"j6geO1eoXRwQ"},"source":["# このセルを下記の手順に従い本文にコピーして，計算してみてください。\n","def suppression_cal(before, after):\n","    '''2音の間での低減量を算出する関数\n","       引数 before：基準となる音データ\n","            after:  処理の効果を評価したい音データ\n","    '''\n","    before_power = np.sum(before**2) / len(before)\n","    after_power = np.sum(after**2)   / len(after)\n","    return 10 * np.log10(after_power / before_power)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"COxWtcqBXRwS"},"source":["具体的手順は以下です。\n","\n","1. 本文ノートブックに「+コード」アイコンで新しいセルを作り，上記の関数定義をそのセルにコピーして，実行することで関数定義を行います。\n","\n","1. 本文ノートブックにおける「# インプット 7.12 （ステップ (1) のコード）」のセルを再度実行します。\n","\n","1. 本文ノートブックにおける「# ステップ (2) のコード」というセルにおいて，以下の2行を捜し，wave_data に 0.0 をかけます（着目したいのは雑音だけですので，信号は不要です）。そのうえで，そのセルを実行します。\n","```\n","for channel_id in range(n_channels):\n","    z[channel_id] = circular_delay(noise, fs, channel_id * tau) + 0.0 * wave_data # 遅延した雑音と，目的音を重ねます。\n","```\n","\n","1. 本文ノートブックにおける「# ステップ (3-a) 録音された全体を一気に処理する場合」というセルにおいて，y を計算した後に以下の2行を追加します。そのうえで，そのセルを実行します。\n","```\n","suppression = suppression_cal(noise, y)\n","print(\"Amound of noise suppression =\", suppression, \"[dB]\")\n","```\n","1. 出力された値は，約 -11 dB という値になりましたか？確認してください。"]},{"cell_type":"markdown","metadata":{"id":"5p9loT0RXRwT"},"source":["(2) すでに，雑音の到来方向 (DOA) を変えた場合に，雑音低減量が異なることは音を聞くことで観測済みである。雑音の DOA を$-90^\\circ$ から$90^\\circ$まで　$1^\\circ$ ごとに変え，雑音低減量を計算しなさい。横軸を DOA とし，縦軸を雑音低減量としたグラフ（空間スペクトルやビームパターンと呼ばれる）を作成すること。\n","\n","【答】「# ステップ(2)のコード」というセルを以下のように加筆・修正したものを以下に示します。 本文ノートブックにおける適当な場所に，「+コード」アイコンで新しいセルを作り，そこに以下のコードをコピーして実行してください。"]},{"cell_type":"code","metadata":{"id":"MaZIiEEyXRwT"},"source":["# ステップ (2) のコード  → 確認問題用に加筆修正\n","n_channels = 20     # マイクロホンの個数\n","d = 7e-3            # マイクロホンの間隔 [m]\n","c = 340.0           # 音速 [m/s]\n","noise_amp = 1000.0  # 雑音の振幅\n","\n","n_samples = 3000                                # 実行時間短縮のため，ポイント数は3000に減らす。\n","z = np.zeros((n_channels, n_samples))           # まず「全マイクロホンの観測データ」を納める，2次元配列を準備します。\n","noise = noise_amp * np.random.randn(n_samples)  # 雑音データを準備します。\n","\n","# --- (この部分は新設) ---\n","suppression = np.zeros(181)  # -90度から90度まで1度刻みなので 181 角度について記録する。\n","\n","# --- マイクロホン間の遅延を計算して，他のマイクロホンに到達した雑音を計算します。 ----\n","for DOAindex in range(-90, 91, 1):\n","    DOA = DOAindex / 180.0 * np.pi \n","    tau = d * np.sin(DOA) / c                      # マイクロホン間の遅延時間を計算します。\n","    for channel_id in range(n_channels):\n","        z[channel_id] = circular_delay(noise[:n_samples], fs, channel_id * tau) #+ wave_data # 遅延した雑音と，目的音を重ねます。\n","\n","    # --- 以下はステップ (3-a) からのコピー ---\n","    y = np.zeros(n_samples)                # アレイからの出力を納める配列を用意して，\n","    for channel_id in range(n_channels):   # 全てのチャネルについて\n","        y += z[channel_id]                 # 単に加算します。 \n","    y = y / n_channels                     # 最後にチャネル総数で除せば，処理は完了です。\n","    suppression[DOAindex+90] =  suppression_cal(noise, y) # 結果を記録\n","\n","# --- (この部分は新設) ---\n","plt.plot(np.arange(-90, 91,1), suppression)\n","plt.xlabel('DOA of noise (deg.)')\n","plt.ylabel('Noise suppression (dB)')\n","plt.xticks(np.arange(-90,91,30))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C1xRTTvxXRwV"},"source":["(3) マイクロホンの間隔を広めに設定して，空間折返し歪が生じる条件では，上記のグラフはどのような特徴をもつか観測すること。ただし，到来信号としては正弦波を用いること（その周波数を様々に変化させて，検討すること）。\n","\n","【答】上記のセルで d = 7e-3 (7 mm) となっている数値を，例えば d = 0.10 (10 cm)と変えます。また，\n","```\n","noise = noise_amp * np.random.randn(n_samples)\n","```\n","の1行を\n","```\n","f = 1000 # [Hz]\n","t = np.arange(n_samples) * sampling_interval\n","noise = noise_amp * np.sin(2 * np.pi * f * t)\n","```\n","の3行に変更します。まだこの設定であれば，空間折返し歪は発生しません（1000 Hz の波長は 34 cm なので，その半波長である 17 cm 以下であれば発生しません）。でも，f = 5000 [Hz] とすると，波長は 6.8 cm であり，半波長 3.4 cm は 10 cm より短いので，しっかりと折返し歪が発生します（DOA が 0$^\\circ$以外にも消去されない場合が発生します）。\n","\n","(4) ここで取り上げた遅延和アレイでは，$M$個のマイクロホンについて，各マイクロホンからの出力に $1/M$ という重みをかけて加算したと見なすことができる（重みの和は 1 である）。これは，「マイクロホン出力の系列を【方形波窓】で切り出した」のと等価である。では，例えば「ハニング窓をかけて切り出す（すなわち，両端のマイクロホンほど重みを小さくする）」をした場合に，(2) で観測したグラフはどのように変化するか，観測すること。\n","\n","【答】上記のセルにおける\n","\n","``` \n","    # --- 以下はステップ (3-a) からのコピー ---\n","    y = np.zeros(n_samples)                # アレイからの出力を納める配列を用意して，\n","    for channel_id in range(n_channels):   # 全てのチャネルについて\n","        y +=  z[channel_id]                # 単に加算します。 \n","```\n","\n","の部分を以下のように加筆します。すなわち，窓関数 w をハニング窓により準備して，かけてから加算するようにします。\n","\n","``` \n","    # --- 以下はステップ (3-a) からのコピー ---\n","    y = np.zeros(n_samples)                # アレイからの出力を納める配列を用意して，\n","    w = hanning( n_channels )              # 窓関数を用意して，\n","    for channel_id in range(n_channels):   # 全てのチャネルについて\n","        y += w[channel_id] * z[channel_id] # 窓掛けをしながら加算します。 \n","```\n","\n","このように窓をかけることで「スペクトルのメインローブが広くなり，サイドローブが低くなる」という変化が見られたでしょう。f を高めに設定（例えば f = 3000）すると効果がよく分かります。\n","\n","(5) マイクロホンアレイの性能を評価するための代表的な尺度は，上記の雑音低減量である。もう一つの代表的な尺度として，SDR (Signal-to-Distortion Ratio) がある。\n","$$\n","{\\rm SDR \\ [dB]} = 20 \\log_{10} \\frac{\\sum_{f} \\left|X(f) \\right|}{\\sum_{f} \\left| \\left| X(f) \\right| - \\left| Y(f) \\right| \\right|\n","}\n","$$\n","ここで，$X(f)$, $Y(f)$ は，それぞれ「本来の目的音のスペクトル」と「処理後に得られた目的音のスペクトル」である。定義から明らかなように，もしpワースペ苦トルとして全く歪がない（$|X(f)| =|Y(f)|$）とすれば分母は0となるので，SDR は $\\infty$ dB となる。この尺度を算出する関数を定義し，実際に (a) の遅延和アレイを実行する前後でSDR はどの程度改善したか，算出してみること。\n","\n","【答】以下に「処理前」と「処理後」の2つの音を与えた場合に低減量を算出する関数 SDR_cal の定義を示します。"]},{"cell_type":"code","metadata":{"id":"mYs7Mx7_XRwW"},"source":["def SDR_cal(x, y):\n","    ''' SDR を計算する関数の定義\n","        引数 x: 原音のデータ\n","             y: 処理後の音のデータ\n","    '''\n","    nsamples = min(len(x), len(y))            # x と y のうち短い系列の点数を計算対象とします。\n","    Xabs = np.abs(np.fft.fft(x[ : nsamples])) # x のスペクトルを求めて，絶対値を計算します。\n","    Yabs = np.abs(np.fft.fft(y[ : nsamples])) # y のスペクトルを求めて，絶対値を計算します。\n","\n","    SDR = 20 * np.log10( np.sum(Xabs) / np.sum(np.abs(Xabs - Yabs))) # 定義どおりに SDR を計算します。\n","    return SDR"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Sb_QVquXRwY"},"source":["具体的手順は以下です。\n","\n","1. 本文ノートブックに「+コード」アイコンで新しいセルを作り，上記の関数定義をそのセルにコピーして，実行することで関数定義を行います。\n","\n","1. 本文ノートブックにおける「# ステップ (1) のコード」，「# ステップ (2) のコード」，「# ステップ (3-a) 録音された全体を一気に処理する場合」を念のため実行します。もし課題(1)で，「# ステップ (2) のコード」というセルにおいて，wave_data に 0.0 をかけるように修正したら，その「0.0 *」をトルしてください。\n","\n","1. 本文ノートブックに「+コード」アイコンで新しいセルを作り，\n","```\n","SDR_cal(wave_data, z[0])\n","```\n","を実行することで，処理前の SDR を計算します。\n","\n","1. 本文ノートブックに「+コード」アイコンで新しいセルを作り，\n","```\n","SDR_cal(wave_data, y)\n","```\n","を実行することで，処理前の SDR を計算します。\n","\n","1. SDRは，処理前：約 $-10$ dB，処理後：約$9$ dB となりましたか？確認してください。\n","\n","1. さらに「# ステップ (2) のコード」における「noise_amp = 1000.0  # 雑音の振幅」という値を例えば 100.0 に変えてから再度実行して，SDRの値と音質劣化の関係を確かめてください。→ SDR はどの程度の値であれば，「歪の影響はない」といえそうですか？\n","\n","補足：上記の SDR の計算では， Xabs と Yabs が全周波数帯を見れば等しいことを仮定しています。もし，その仮定が成り立たない場合には，事前に Yabs のパワーが Xabsと等しくなるように調整します。\n","\n","(6) 本節の冒頭で，遅延和アレイでは「マイクロホンからの出力に適切な遅延を付加して加算する」ことを述べた。その遅延量は「標本化周期より小さい値」であってもよい（**分数遅延**と呼ばれる）。それを時間領域だけで実現するとする手続きは，本節でも用いた「位相回転を利用した遅延」を利用することである。さて，分数遅延を含む遅延和アレイ処理を，周波数領域まで利用して実現する手続きを述べなさい。\n","\n","【答】以下の手順で実現できます。\n","\n","1. 周波数領域で設計した分数遅延フィルタを逆フーリエ変換して時間領域信号に戻す。（第5章記載の手法）\n","\n","1. これに後ろに0を詰めてFFTして周波数領域で畳み込み演算を実施する。（第6章記載の方法）\n","\n","1. 最後にそのフレームの時間信号の和を取る。\n","\n","若干複雑な感じがしますが，周波数領域で求めたフィルタをそのまま周波数領域で掛け算するのは，円状畳み込みによる折返歪（エリアシング）を生むこと，またHanning窓を掛けることは，周波数領域では周波数方向の平均になり応答がなまる非線形処理である，といったことを回避しているのです。"]}]}